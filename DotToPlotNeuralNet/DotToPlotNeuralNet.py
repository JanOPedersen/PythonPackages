import numpy as np
import math
import torchview
import graphviz
import re
import xml.etree.ElementTree as ET
from graph.graph import graph
from collections import namedtuple

import sys
sys.path.append('../')
from pycore2.tikzeng import *
from pycore2.blocks  import *
import pycore2

graphviz.set_jupyter_format('png')

class DotToPlotNeuralNet:
    '''This class takes as constructor an input a dot file as generated by torchview.draw_graph(...) 
    and generates a py file (Python source code) that can used as input for the PlotNeuralNet 
    Python application. 
    
    Refactoring suggestions:

    1. Instead of using all these index lists, we should implement a class decorator of the
       graph class, which would allow us to use only the graph class. We would then need to
       prune the graph further, using already implemented functions in the graph class. For 
       instance, a sequence of nodes like "Conv2d -> ReLU -> Conv2d -> ReLU -> Conv2d -> ReLU",
       would be pruned to a single node. 

    2. Converting the main path of the graph into a string and parsing it, is a bit cumbersome.
       Maybe this should be implemented in the graph class, also. 

    3. build_graph() should be implemented in the graph class, also.

    4. ...
    '''
    
    def __init__(self,dotString: str):
        self.nodeXML = re.findall('\[label.*?(<TABLE.*?</TABLE>).*?\](\w*\d+)', \
                                  dotString.replace('\n','').replace('\t',''))
        self.edges = re.findall('(\d+) -> (\d+)',dotString)
        self.NodeInfoRec = namedtuple('NodeInfoRec', ['name', 'depth', 'height', 'width'])
        self.ParsedNodeInfoRec = namedtuple('ParsedNodeInfoRec', ['type', 'depth', 'height', 'width',\
                                            'displayDepth','displayHeight','displayWidth','fromSkip'])
        self.projectPath = os.path.dirname(pycore2.__file__) + '/'
        self.inputFileName = None
        self.visibleNodes = ['ReLU','Conv2d','MaxPool2d','ConvTranspose2d','Flatten', 'Linear','add_']

    def extractNodeInfo(self, string:str) -> list:
        parsedXML = ET.fromstring(string)
        if (len(parsedXML) > 1):
            return [parsedXML[0][0].text,parsedXML[1][1].text]
        else:
            return [parsedXML[0][0].text,parsedXML[0][1].text]

    # NOTE: this does not work for all input shape combinations, like '(2, 8)', so we
    # will need to take the different tensor dimensions into account. The case of 
    # '(1, 3, 572, 572)' is handled by recognizing the 1 as a dummy dimension.
    def extract_tensor_dimensions(self, lst:str) -> list:
        '''Given an input like ['input-tensor', '(1, 3, 572, 572)'],
        we generate an output of form [3, 572, 572]'''
        lst = re.findall('\((.*)\)',lst[-1])[0].split(',')
        return [int(item) for item in lst[1:4]]
    
    def transpose_list(self, lst:list) -> list:
        '''Given a list like:
        [[1, 3, 572, 572], [1, 64, 570, 570], [1, 64, 568, 568], [1, 64, 284, 284]]
        this is transformed into:
        [[3, 64, 64, 64], [572, 570, 568, 284], [572, 570, 568, 284]]
        which is a transposition followed by removal of the first column'''
        lst=[list(item) for item in lst]
        return [list(i) for i in zip(*lst)]
    
    def extract_node_info(self) -> None: 
        '''Given found we generate a dictionary of named tupples to be used for creating our graphics
        The created dictionary contains items of the form:
            0: Rec(name='input-tensor', depth=3, height=572, width=572),
            1: Rec(name='Conv2d', depth=64, height=570, width=570),
        '''
        res = []
        indicies=[int(item[1]) for item in self.nodeXML]
        indicies = indicies[-1:] + indicies[:-1] # Rotate list
        for item in self.nodeXML:
            txt = self.extractNodeInfo(item[0])
            shapes = self.extract_tensor_dimensions(txt)
            if len(shapes) == 3:
                res.append([txt[0],shapes[0],shapes[1],shapes[2]])
            else:
                res.append([txt[0],1, 1,shapes[0]])

        names = [item[0] for item in res]
        dephts = [item[1] for item in res]
        heights = [item[2] for item in res]
        widths = [item[3] for item in res]

        lists = self.transpose_list([names,dephts,heights,widths])
        tups = [self.NodeInfoRec(item[0],item[1],item[2],item[3]) for item in lists]
        self.Node_info_dict = {indicies[i]: tups[i] for i in range(len(indicies))} 
        
    def list_nice_to_display(self, lst: list, min_val: int, max_val: int) -> dict:
        '''A list of for instance dephts like:
        [64,64,64,128,128,128,256,256,256,512,512,512,1024,1024,512,512,512,256,256,256,128,128,128,64,64,64,2]
        ... which gives unreadable variations in size, is mapped into for instance:
        [3,3,3,5,5,5,7,7,7,9,9,9,10,10,9,9,9,7,7,7,5,5,5,3,3,3,1]       
        ... with reduced and evenly spaced visual elements
        '''
        unique_list = list(dict.fromkeys(lst))
        altered_list = [math.ceil(item) for item in np.linspace(min_val,max_val,len(unique_list))]
        unique_list.sort()
        return dict(map(lambda i,j : (i,j) , unique_list,altered_list))
    
    def extract_string_representation(self) -> str:
        '''Given a list of nodes making up our main path, we represent it as a
        string, like "crcrpcrcrpcrcrcrpcrcrcrpcrcrcrplrlrl"'''
        string_repr = ''
        node_type_to_char = {'Conv2d':'c','MaxPool2d':'p','ConvTranspose2d':'u',\
                             'Flatten':'f','Linear':'l','ReLU':'r','add_':'a'}
        prev_dims = None
        for node in self.raw_nodes:       
            char = node_type_to_char.get(node.type)
            if char == 'c':
                if not prev_dims:
                    prev_dims = (node.height,node.width)
                    string_repr += 'c'
                else:
                    if (node.height,node.width) != prev_dims or string_repr[-1] == 'C':
                        string_repr += 'C'
                    else:
                        string_repr += 'c'
            else:
                string_repr += (char if char is not None else 'x')

            if char in ['p','u','f','l','a']:
                prev_dims = None
        
        return string_repr
            
    def parse_string_representation(self,string_repr:str) -> tuple:
        ''' Given a string representation of the main parh like
        "crcrpcrcrpcrcrcrpcrcrcrpcrcrcrplrlrl", we replace blocks of nodes
        like "crcrp" with aggregated blocks like "Cp>", where C is a conv block
        of (conv,relu), and > is an arrow to a new block to be displayed.
        We return a tuple of resulting string ("Cp>Cp>Cp>Cp>Cp>L>L>l"), locataions
        of input blocks ([(0, 4), (4, 5), (5, 9), (9, 10), (10, 16), ...]) and
        output blocks ([(0, 2), (2, 3), (3, 5), (5, 6), (6, 8), ...])'''   
        in_patterns = [r'((?:cr){2,})','(lr)','(p)','(l)','(u)','(Cr)','(cr)','(a)','(c)']
        out_patterns = ['C','L>','P>','l','>U','C','C','}A}','C']
        in_pattern = '|'.join(in_patterns)
        out_pattern = '|'.join(out_patterns)

        def parse_sub_pattern(match_obj):
            for i in range(1, len(in_patterns) + 1):
                if match_obj.group(i) is not None:
                    return out_patterns[i - 1]

        out = re.sub(in_pattern, parse_sub_pattern, string_repr)
        in_spans = [item.span() for item in re.finditer(in_pattern,string_repr)]
        out_spans = [item.span() for item in re.finditer(out_pattern,out)]
        return (out,in_spans,out_spans)
    
    def out_index_to_group_index(self,out:list) -> list:
        '''Given list of out group index ranges, 
        like [(0, 1),(1, 3),(3, 4),(4, 6),(6, 7),(7, 9),(9, 1),...]
        we compute for each index in each group its position in that list; i.e
        [0, 1, 1, 2, 3, 3, 4, 5, 5, ...]'''
        maxIndex = max([item for sublist in out for item in sublist])
        ranges = [list(range(item[0],item[1])) for item in out]
        group_indicies = [-1]*maxIndex
        for i in range(len(ranges)):
            for val in ranges[i]:
                group_indicies[val] = i
        return group_indicies
    
    def build_graph(self) -> None:
        '''Given self.edges, we build the graph
            NOTE: This should be implemented in the graph class, 
            with the list ['ReLU','Conv2d','MaxPool2d','ConvTranspose2d','Flatten', 'Linear']
            as an input variable'''
        res = [(int(item[0]),int(item[1])) for item in self.edges]
        adj = {}
        self.g = graph(adj)
        for item in res:
            self.g.AddEdge(item)
            
        # At this point in time we should run self.Node_info_dict[node].name
        # on each node to see if it should be visible. Then we prune the nodes
        # and finally compute the longest path
        self.visible_nodes = set()
        for node in self.g.getVertices():
            if self.Node_info_dict[node].name in self.visibleNodes:
                self.visible_nodes.add(node)
                
        self.g.prune_nodes(self.visible_nodes) 
        (root,leaf) = (self.g.findRootVertices()[0],self.g.findLeafVertices()[0])
        self.g.longestDistances(root)
        self.g.longestPath(leaf)
        
        skip_connections = self.g.find_skip_connections()
        self.reverse_skip_connections = {item[1]:item[0] for item in skip_connections}  
    
    def construct_raw_nodes(self) -> None:
        '''We would now like to parse (regular parse) the self.g.v_list list and create a list of aggregated nodes
        that we can use create the visual elements. We will use the following rules:
        A Conv2d node followed by a Relu node is replaced by a Conv2dRelu node
        A series of Conv2dRelu nodes followed by a Pool node is replaced by a to_ConvConvRelu node and an arrow
        to the next block'''
        self.raw_nodes = []
        self.node_indices = []
        (self.dephts,self.heights,self.widths) = ([],[],[])
        self.node_indices = [item for item in self.g.v_list]
        
        self.reverse_node_indicies = [-1]*(max(self.node_indices) + 1)
        for idx, i in enumerate(self.node_indices):
            self.reverse_node_indicies[i] = idx
        
        for node in self.g.v_list:
            node_type = self.Node_info_dict[node].name
            # Later, we serialize the raw nodes into a string, so we need to know
            # how to get back from a position in the string into a node index
            if node_type in ['Conv2d','MaxPool2d','ConvTranspose2d','Flatten', 'Linear','add_']:
                depth = self.Node_info_dict[node].depth
                height = self.Node_info_dict[node].height
                width = self.Node_info_dict[node].width
                self.dephts.append(depth)
                self.heights.append(height)
                self.widths.append(width)                    
                sourceNode =  self.reverse_node_indicies[self.reverse_skip_connections[node]] if \
                    node in self.reverse_skip_connections else None
                
                self.raw_nodes.append(self.ParsedNodeInfoRec(node_type,depth,height,width,None,None,None,sourceNode))
            elif node_type in ['ReLU']:
                self.raw_nodes.append(self.ParsedNodeInfoRec(node_type,None,None,None,None,None,None,None))
            else:
                self.raw_nodes.append(self.ParsedNodeInfoRec(node_type,None,None,None,None,None,None,None))
                             
    def update_raw_nodes(self) -> None:
        # calculate display dimensions
        depth_list_display = self.list_nice_to_display(self.dephts,1,10)
        width_list_display = self.list_nice_to_display(self.widths,8,40)
        height_list_display = self.list_nice_to_display(self.heights,8,40)
              
        # Update the nodes with display dimensions    
        for i in range(len(self.raw_nodes)):
            node = self.raw_nodes[i]
            if node.type in ['Conv2d','MaxPool2d','ConvTranspose2d','Flatten', 'Linear']:
                displayDepth = depth_list_display[node.depth]
                displayHeight = height_list_display[node.height]
                displayWidth = width_list_display[node.width]
                
                j = self.node_indices[i]
                fromSkip = None
                if j in self.reverse_skip_connections:
                    fromSkip = self.reverse_node_indicies[self.reverse_skip_connections[j]]
                node = self.ParsedNodeInfoRec(node.type,node.depth,node.height,node.width,\
                                          displayDepth,displayHeight,displayWidth,fromSkip)
                self.raw_nodes[i] = node
                
    def extract_connectivity(self) -> None:
        '''Given the self.Node_info_dict dictionary with basic tensor shape information per
        node and a list of edges of form  ('0','1'), ('1','2'), we create a more comprehensive
        dictionary with items of the form:
            CombinedRec(index=1, name='conv1', to='(0,0,0)', displayDepth=3, displayHeight=40, displayWidth=40),
            CombinedRec(index=3, name='conv2', to='(conv1--east)', displayDepth=3, displayHeight=39, displayWidth=39),
        '''
        self.build_graph()            
        self.construct_raw_nodes()
        self.update_raw_nodes()
        string_rep = self.extract_string_representation()  
        (parsed_string_rep,in_spans,out_spans) = self.parse_string_representation(string_rep)
         
        # Given a character in parsed_string_rep, we need to know what code segment it came from
        
        # Generate a node aggregated list. This is essentially the opposite of the parsing
        # exercise above, where we generated a string from a list. Now we generate a list from
        # a string
        self.aggregated_nodes = []
        (convCounter,poolCounter,unpoolCounter,flattenCounter,linearCounter,addCounter) = (1,1,1,1,1,1)
        offset = '(0,0,0)'
        prev_node_name = None
        source_name = None
        
        # Check that all constant parameters are constant, so that we can use to_NConvRelu(...)
        # If the need arises, we may have to generalize to_NConvRelu(...)
        def all_equal(lst:list) -> bool:
            return all(item == lst[0] for item in lst)
        
        def update_offset(source_name:str = None,dest_name:str=None):
            nonlocal offset,prev_node_name
            
            if source_name:
                self.aggregated_nodes.append(to_skip( of=source_name,to=dest_name, pos=1.25))
            
            if offset != '(0,0,0)':
                self.aggregated_nodes.append(to_connection(prev_node_name,node_name))
            offset = '(0,0,0)'
            prev_node_name = node_name
        
        # record skip connections
        sourceNames = {}
        sourceNodes = {item.fromSkip for item in self.raw_nodes if item.fromSkip is not None}
        group_indicies = self.out_index_to_group_index(out_spans)

        def check_skip_connection(j:int) -> None:
            nonlocal source_name
            if j in sourceNodes:
                sourceNames[j] = node_name
            if self.raw_nodes[j].fromSkip:
                source_name = sourceNames[self.raw_nodes[j].fromSkip]
                       
        for l in range(len(parsed_string_rep)):
            to_node = '(' + prev_node_name + '-east)' if prev_node_name is not None else '(0,0,0)'
            k = group_indicies[l]
                        
            match parsed_string_rep[l]:
                case 'C':
                    
                    #TODO: we don't need the above as it is already checked in the 
                    # extract_string_representation(...) function, but we should add some
                    # guards
                    source_name = None
                    node_name = 'conv' + str(convCounter)
                    (depths,heights,widths,displayDepths,displayHeights,displayWidths) = ([],[],[],[],[],[])
                    for j in range(in_spans[k][0],in_spans[k][1]):
                        if string_rep[j] == 'c' or string_rep[j] == 'C':
                            depths.append(self.raw_nodes[j].depth) # may vary
                            heights.append(self.raw_nodes[j].height) # should be constant
                            widths.append(self.raw_nodes[j].width) # should be constant
                            displayDepths.append(self.raw_nodes[j].displayDepth) # may vary
                            displayHeights.append(self.raw_nodes[j].displayHeight) # should be constant
                            displayWidths.append(self.raw_nodes[j].displayWidth) # should be constant     
                        check_skip_connection(j)
                           
                    (depths,heights,widths,displayDepths,displayHeights,displayWidths) = \
                    (tuple(depths),tuple(heights),tuple(widths),\
                     tuple(displayDepths),tuple(displayHeights),tuple(displayWidths)) 
                    
                    assert all_equal(heights)
                    assert all_equal(widths)
                    assert all_equal(displayHeights)
                    assert all_equal(displayWidths)
                     
                    # if the width and heights of our (conv,relu) sub-blocks are different
                    # from each other, we can not rely on to_NConvRelu(...) to draw, the
                    # combined block as it assumes constant width and height. Instead, we
                    # call to_NConvRelu(...) a number of times. to_NConvRelu(...) does not quite
                    # work for N=1, so we use N=2 and have the second block have depth = 0 and
                    # caption = "" (empty string). This hack works.
                    edge_size = max(displayWidths[0],displayHeights[0]) 
                    if len(depths) == 1: # pad with zero depth "dummy" layer to fix display bug
                        self.aggregated_nodes.append(to_NConvRelu(name=node_name,s_filer=widths[0],\
                                 n_filer=(depths[0],0),\
                                 width=(displayDepths[0],0),height=edge_size,depth=edge_size,\
                                 offset=offset,to=to_node)) 
                    else:
                        self.aggregated_nodes.append(to_NConvRelu(name=node_name,s_filer=widths[0],\
                                 n_filer=depths,\
                                 width=displayDepths,height=edge_size,depth=edge_size,\
                                 offset=offset,to=to_node)) 
                                        
                    update_offset(source_name,node_name)
                    convCounter += 1

                case 'L': 
                    source_name = None
                    for j in range(in_spans[k][0],in_spans[k][1]):
                        if string_rep[j] == 'l':
                            displayWidth = self.raw_nodes[j].displayWidth
                            width = self.raw_nodes[j].width
                        check_skip_connection(j)
                            
                    node_name = 'linear' + str(linearCounter)
                    self.aggregated_nodes.append(to_FullyConnectedRelu(name=node_name,s_filer=width,\
                            depth=displayWidth,caption='fc' + str(linearCounter),offset=offset,to=to_node)) 
                                            
                    update_offset(source_name,node_name)    
                    linearCounter += 1

                case 'l':
                    source_name = None
                    for j in range(in_spans[k][0],in_spans[k][1]):
                        if string_rep[j] == 'l':
                            displayWidth = self.raw_nodes[j].displayWidth 
                            width = self.raw_nodes[j].width
                        check_skip_connection(j)
                            
                    node_name = 'linear' + str(linearCounter)
                    self.aggregated_nodes.append(to_FullyConnected(name=node_name,s_filer=width,depth=displayWidth,\
                            caption='fc' + str(linearCounter),offset=offset,to=to_node)) 
                     
                    update_offset(source_name,node_name)
                    linearCounter += 1

                case 'P':
                    source_name = None
                    for j in range(in_spans[k][0],in_spans[k][1]):
                        if string_rep[j] == 'p':
                            displayWidth = self.raw_nodes[j].displayWidth    
                            displayHeight = self.raw_nodes[j].displayHeight 
                        check_skip_connection(j)
                            
                    edge_size = max(displayWidth,displayHeight) 
                    node_name = 'pool' + str(poolCounter)
                    self.aggregated_nodes.append(to_Pool(name=node_name,depth=edge_size ,height=edge_size,\
                            offset=offset,to=to_node)) 
                                        
                    update_offset(source_name,node_name)
                    poolCounter += 1

                case 'U':
                    source_name = None
                    for j in range(in_spans[k][0],in_spans[k][1]):
                        if string_rep[j] == 'u':
                            displayWidth = self.raw_nodes[j].displayWidth    
                            displayHeight = self.raw_nodes[j].displayHeight 
                        check_skip_connection(j)
                    edge_size = max(displayWidth,displayHeight) 
                    node_name = 'unpool' + str(unpoolCounter)
                    self.aggregated_nodes.append(to_UnPool(name=node_name,depth=edge_size ,height=edge_size,\
                              offset=offset,to=to_node)) 
                    
                    update_offset(source_name,node_name)
                    unpoolCounter += 1

                case 'A':
                    source_name = None
                    #for j in range(in_spans[k][0],in_spans[k][1]):    
                    #    check_skip_connection(j)
                    node_name = 'add' + str(addCounter)
                    self.aggregated_nodes.append(to_Sum(name=node_name,offset=offset,to=to_node)) 
                    update_offset(source_name,node_name)
                    addCounter += 1
                      
                case '>':
                    offset = '(2,0,0)'
                    
                case '}':
                    offset = '(0.9,0,0)'
                                                        
    def create_PlotNeuralNet_content(self, fileName: str = None) -> list:
        '''From the two dictionaries self.combinedList and Node_info_dict we generate
        out puts of the form:
            to_Conv("conv1", 570, 64, offset="(0,0,0)", to="(0,0,0)", height=40, depth=40, width=3 ),
            to_Conv("conv2", 568, 64, offset="(0,0,0)", to="(conv1--east)", height=39, depth=39, width=3 ),
            Note that the indicies of self.combinedList is a subset of the indicies if Node_info_dict
            Because the in the former case, invisible nodes have been removed.
        '''
        self.extract_node_info()        
        self.extract_connectivity()
        self.plotNNString = []
        self.plotNNString.append(to_head(self.projectPath))
        self.plotNNString.append(to_cor())
        self.plotNNString.append(to_begin())
        
        if fileName:
            self.plotNNString.append(to_input(fileName))
            self.inputFileName = fileName
        
        for node in self.aggregated_nodes:
            self.plotNNString.append(node)
        
        self.plotNNString.append(to_end()) 
        return self.plotNNString
                
    def create_pdf(self,name: str) -> None:
        namefile = str(name).split('.')[0]
        to_generate(self.plotNNString, namefile + '.tex' )
        old_dir = os.getcwd()
        if self.inputFileName is not None:
            os.system('cp ' + self.inputFileName + ' "' + self.projectPath + '/temp/"')
        os.chdir(self.projectPath + '/temp')
        os.system("pdflatex " + namefile + ".tex")
        os.chdir(old_dir)
        os.system('cp "' + self.projectPath + '/temp/"' + namefile +   '.pdf "' + old_dir + '"') 